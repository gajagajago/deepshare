.TH "job_container.conf" "5" "Slurm Configuration File" "January 2022" "Slurm Configuration File"

.SH "NAME"
job_container.conf \- Slurm configuration file for job_container/tmpfs plugin

.SH "DESCRIPTION"

\fBjob_container.conf\fP is an ASCII file which defines parameters used by
Slurm's job_container/tmpfs plugin. The plugin reads the
job_container.conf file to find out the configuration settings. Based on them it
constructs a private mount namespace for the job and mounts /tmp and
/dev/shm inside it. This gives the job a private view of /tmp and
/dev/shm. /tmp is mounted inside a location that is specified as 'BasePath' in
job_container.conf file. To make use of this plugin, 'PrologFlags=Contain' must
be present in your \fBslurm.conf\fP file.

The file will always be located in the same directory as the \fBslurm.conf\fR.

.LP
If using the \fBjob_container.conf\fR file to define a namespace available to
nodes the first parameter on the line should be \fBNodeName\fR. If configuring a
namespace without specifying nodes, the first parameter on the line
should be \fBBasePath\fR.

.LP
Parameter names are case insensitive.
Any text following a "#" in the configuration file is treated
as a comment through the end of that line.
Changes to the configuration file take effect upon restart of Slurm daemons.

.LP
The following job_container.conf parameters are defined to control the behavior
of the job_container/tmpfs plugin.

.TP
\fBAutoBasePath\fR
This determines if plugin should create the BasePath directory or not. Set it
to 'true' if directory is not pre\-created before slurm startup. If set to true,
the directory is created with permission 0755. Directory is not deleted during
slurm shutdown. If set to 'false' or not specified, plugin would expect
directory to exist. This option can be used on a global or per\-line basis.
This parameter is optional.
.IP

.TP
\fBBasePath\fR
Specify the \fIPATH\fR that the tmpfs plugin should use to mount private /tmp
to. This path must be readable and writable by the plugin. The plugin also
constructs a directory for each job inside this path, which is then used for
mounting. The \fBBasePath\fR gets mounted as 'private' during slurmd start
and remains mounted until shutdown.

\fBNOTE\fR: The \fBBasePath\fR parameter should not be configured to use
/tmp or /dev/shm. Using these directories will cause conflicts when trying
to mount and unmount the private directories for the job.
.IP

.TP
\fBInitScript\fR
Specify fully qualified pathname of an optional initialization script. This
script is run before the namespace construction of a job. It can be used to
make the job join additional namespaces prior to the construction of /tmp
namespace or it can be used for any site\-specific setup. This parameter is
optional.
.IP

.TP
\fBNodeName\fR
A NodeName specification can be used to permit one job_container.conf
file to be used for all compute nodes in a cluster by specifying the node(s)
that each line should apply to.
The NodeName specification can use a Slurm hostlist specification as shown in
the example below. This parameter is optional.
.IP

.SH "EXAMPLE"
.TP
\fB/etc/slurm/job_container.conf\fR:
.IP
.nf
###
# Sample job_container.conf file 1
# Define 2 basepaths
# The first will only be on largemem[1\-2] and it will automatically created.
# The second will only be on gpu[1\-10], will be expected to exist and will run
#     an initscript before each job.
###
NodeName=largemem[1\-2] AutoBasePath=true BasePath=/var/nvme/storage
NodeName=gpu[1\-10] BasePath=/var/nvme/storage InitScript=/etc/slurm/init.sh
.fi

.nf
###
# Sample job_container.conf file 2
# Define 1 basepath that will be on all nodes and automatically created.
###
AutoBasePath=true
BasePath=/var/nvme/storage
.fi

.TP
\fB/etc/slurm/slurm.conf\fR:
These are the entries required in \fBslurm.conf\fR to activate the
job_container/tmpfs plugin.
.IP
.nf
###
# Slurm configuration need to use job_container/tmpfs plugin
###
JobContainerType=job_container/tmpfs
.fi

.SH "NOTES"
.LP
If any parameters in job_container.conf are changed while slurm is running, then
slurmd on the respective nodes will need to be
restarted for changes to take effect. Additionally this can be disruptive to
jobs already running on the node. So care must be taken to make sure no jobs
are running if any changes to job_container.conf are deployed.

Restarting slurmd is safe and non\-disruptive to running jobs, as long as
job_container.conf is not changed between restarts in which case above point
applies.


.SH "COPYING"
Copyright (C) 2021 Regents of the University of California
Produced at Lawrence Berkeley National Laboratory
.br
Copyright (C) 2021\-2022 SchedMD LLC.

.LP
This file is part of Slurm, a resource management program.
For details, see <https://slurm.schedmd.com/>.
.LP
Slurm is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free
Software Foundation; either version 2 of the License, or (at your option)
any later version.
.LP
Slurm is distributed in the hope that it will be useful, but WITHOUT ANY
WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more
details.

.SH "SEE ALSO"
.LP
\fBslurm.conf\fR(5)
